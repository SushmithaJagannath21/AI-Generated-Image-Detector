# AI-Generated Image Detector

The **AI-Generated Image Detector** is a machine learning project designed to detect and classify images generated by artificial intelligence models. This tool aims to differentiate between AI-generated images and real-world images by utilizing deep learning techniques.

## Features
- **AI Image Detection**: Trains a model to detect whether an image is AI-generated or real using various pre-trained models.
- **Model Preprocessing**: Includes data preprocessing pipelines for image enhancement and preparation for model training.
- **Web Application**: Provides a user-friendly web interface for users to upload and test images for AI-generated content.
- **Visualization Tools**: Visualize the results of model predictions and data insights.

## Technologies Used
- **Python**: Core programming language used for the project.
- **TensorFlow / PyTorch**: Deep learning frameworks used for building and training the model.
- **Jupyter Notebook**: For prototyping and developing machine learning models.
- **Flask**: Framework used to build the web interface for image detection.
- **Hugging Face**: Used for model configuration and integration.
- **Makefile**: Automates the build and model training processes.

## Project Structure

```bash
├── AI_generate/                  # Contains data and scripts for generating AI images
├── hugging_face_config/           # Configuration files for Hugging Face models
├── model_preprossing/             # Preprocessing scripts for image data
├── model_train/                   # Model training scripts
├── pic/                           # Sample images for testing
├── visualization/                 # Visualization scripts for analyzing model predictions
├── web_app/                       # Flask web application for image uploads and detection
├── Makefile                       # Commands for building, training, and deploying models
├── README.md                      # Project documentation
├── requirements.txt               # Python dependencies for the project

